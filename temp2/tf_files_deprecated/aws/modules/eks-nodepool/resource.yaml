---
resource:
  - aws_iam_role:
    eks_control_plane_role:
      name: ${var.vpc_name}_EKS_${var.nodepool}_role
      assume_role_policy: "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}"
  - aws_iam_role_policy_attachment:
    eks-policy-AmazonEKSClusterPolicy:
      policy_arn: arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
      role: ${aws_iam_role.eks_control_plane_role.name}
  - aws_iam_role_policy_attachment:
    eks-policy-AmazonEKSServicePolicy:
      policy_arn: arn:aws:iam::aws:policy/AmazonEKSServicePolicy
      role: ${aws_iam_role.eks_control_plane_role.name}
  - aws_iam_role_policy_attachment:
    bucket_write:
      policy_arn: arn:aws:iam::${data.aws_caller_identity.current.account_id}:policy/bucket_writer_logs-${var.vpc_name}-gen3
      role: ${aws_iam_role.eks_control_plane_role.name}
  - aws_iam_role_policy_attachment:
    eks-policy-AmazonSSMManagedInstanceCore:
      policy_arn: arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
      role: ${aws_iam_role.eks_control_plane_role.name}
  - aws_iam_role:
    eks_node_role:
      name: eks_${var.vpc_name}_nodepool_${var.nodepool}_role
      assume_role_policy: "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}"
  - aws_iam_policy:
    cwl_access_policy:
      name: ${var.vpc_name}_EKS_nodepool_${var.nodepool}_access_to_cloudwatchlogs
      description: In order to avoid the creation of users and keys, we are using roles and policies.
      policy: "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"logs:DescribeLogGroups\",\n            \"Resource\": \"arn:aws:logs:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:log-group::log-stream:*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:CreateLogStream\",\n                \"logs:PutLogEvents\",\n                \"logs:DescribeLogStreams\"\n            ],\n            \"Resource\": \"arn:aws:logs:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:log-group:${var.vpc_name}:log-stream:*\"\n        }\n    ]\n}"
  - aws_iam_policy:
    access_to_kernels:
      name: ${var.vpc_name}_EKS_nodepool_${var.nodepool}_kernel_access
      description: To access custom Kernels
      policy: "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:List*\",\n                \"s3:Get*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::gen3-kernels/*\",\n                \"arn:aws:s3:::gen3-kernels\",\n                \"arn:aws:s3:::qualys-agentpackage\",\n                \"arn:aws:s3:::qualys-agentpackage/*\"\n            ]\n        }\n    ]\n}"
  - aws_iam_policy:
    asg_access:
      name: ${var.vpc_name}_EKS_nodepool_${var.nodepool}_autoscaling_access
      description: Allow the deployment cluster-autoscaler to add or terminate instances accordingly
      policy: "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"autoscaling:DescribeAutoScalingGroups\",\n                \"autoscaling:DescribeAutoScalingInstances\",\n                \"autoscaling:DescribeTags\",\n                \"autoscaling:SetDesiredCapacity\",\n                \"autoscaling:TerminateInstanceInAutoScalingGroup\",\n                \"autoscaling:DescribeLaunchConfigurations\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}"
  - aws_iam_role_policy_attachment:
    eks-node-AmazonEKSWorkerNodePolicy:
      policy_arn: arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
      role: ${aws_iam_role.eks_node_role.name}
  - aws_iam_role_policy_attachment:
    eks-node-AmazonEKS_CNI_Policy:
      policy_arn: arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
      role: ${aws_iam_role.eks_node_role.name}
  - aws_iam_role_policy_attachment:
    eks-node-AmazonEC2ContainerRegistryReadOnly:
      policy_arn: arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
      role: ${aws_iam_role.eks_node_role.name}
  - aws_iam_role_policy_attachment:
    cloudwatch_logs_access:
      policy_arn: ${aws_iam_policy.cwl_access_policy.arn}
      role: ${aws_iam_role.eks_node_role.name}
  - aws_iam_role_policy_attachment:
    asg_access:
      policy_arn: ${aws_iam_policy.asg_access.arn}
      role: ${aws_iam_role.eks_node_role.name}
  - aws_iam_role_policy_attachment:
    kernel_access:
      policy_arn: ${aws_iam_policy.access_to_kernels.arn}
      role: ${aws_iam_role.eks_node_role.name}
  - aws_iam_instance_profile:
    eks_node_instance_profile:
      name: ${var.vpc_name}_EKS_nodepool_${var.nodepool}
      role: ${aws_iam_role.eks_node_role.name}
  - aws_security_group:
    eks_nodes_sg:
      name: ${var.vpc_name}_EKS_nodepool_${var.nodepool}_sg
      description: 'Security group for all nodes in pool ${var.nodepool} in the EKS cluster [${var.vpc_name}] '
      vpc_id: ${data.aws_vpc.the_vpc.id}
      egress:
        - from_port: 0
        to_port: 0
        protocol: '-1'
        cidr_blocks:
          - 0.0.0.0/0
      tags: "${\n    map(\n     \"Name\", \"${var.vpc_name}-nodes-sg-${var.nodepool}\",\n     \"kubernetes.io/cluster/${var.vpc_name}\", \"owned\",\n    )\n  }"
  - aws_security_group_rule:
    https_nodes_to_plane:
      type: ingress
      from_port: 443
      to_port: 443
      protocol: tcp
      security_group_id: ${var.control_plane_sg}
      source_security_group_id: ${aws_security_group.eks_nodes_sg.id}
      depends_on:
        - aws_security_group.eks_nodes_sg
  - aws_security_group_rule:
    communication_plane_to_nodes:
      type: ingress
      from_port: 80
      to_port: 65534
      protocol: tcp
      security_group_id: ${aws_security_group.eks_nodes_sg.id}
      source_security_group_id: ${var.control_plane_sg}
      depends_on:
        - aws_security_group.eks_nodes_sg
  - aws_security_group_rule:
    nodes_internode_communications:
      type: ingress
      from_port: 0
      to_port: 0
      protocol: '-1'
      description: allow nodes to communicate with each other
      security_group_id: ${aws_security_group.eks_nodes_sg.id}
      self: true
  - aws_security_group_rule:
    nodes_interpool_communications:
      type: ingress
      from_port: 0
      to_port: 0
      protocol: '-1'
      description: allow default nodes to communicate with each other
      security_group_id: ${aws_security_group.eks_nodes_sg.id}
      source_security_group_id: ${var.default_nodepool_sg}
  - aws_launch_configuration:
    eks_launch_configuration:
      associate_public_ip_address: false
      iam_instance_profile: ${aws_iam_instance_profile.eks_node_instance_profile.name}
      image_id: ${var.fips_enabled_ami}
      instance_type: ${var.nodepool_instance_type}
      name_prefix: eks-${var.vpc_name}-nodepool-${var.nodepool}
      security_groups:
        - ${aws_security_group.eks_nodes_sg.id}
        - ${aws_security_group.ssh.id}
      user_data_base64: ${base64encode(data.template_file.bootstrap.rendered)}
      key_name: ${var.ec2_keyname}
      root_block_device:
        - volume_size: ${var.nodepool_worker_drive_size}
      lifecycle:
        - create_before_destroy: true
  - aws_autoscaling_group:
    eks_autoscaling_group:
      desired_capacity: ${var.nodepool_asg_desired_capacity}
      launch_configuration: ${aws_launch_configuration.eks_launch_configuration.id}
      max_size: ${var.nodepool_asg_max_size}
      min_size: ${var.nodepool_asg_min_size}
      name: eks-${var.nodepool}worker-node-${var.vpc_name}
      vpc_zone_identifier:
        - ${var.eks_private_subnets}
      tag:
        - key: Environment
        value: ${var.vpc_name}
        propagate_at_launch: true
        - key: Name
        value: eks-${var.vpc_name}-${var.nodepool}
        propagate_at_launch: true
        - key: kubernetes.io/cluster/${var.vpc_name}
        value: owned
        propagate_at_launch: true
        - key: k8s.io/cluster-autoscaler/enabled
        value: ''
        propagate_at_launch: true
        - key: k8s.io/cluster-type/eks
        value: ''
        propagate_at_launch: true
        - key: k8s.io/nodepool/${var.nodepool}
        value: ''
        propagate_at_launch: true
        - key: k8s.io/cluster-autoscaler/node-template/label/role
        value: ${var.nodepool}
        propagate_at_launch: true
        - key: k8s.io/cluster-autoscaler/node-template/taint/role
        value: ${var.nodepool}:NoSchedule
        propagate_at_launch: true
      lifecycle:
        - {}
  - aws_security_group:
    ssh:
      name: ssh_eks_${var.vpc_name}-nodepool-${var.nodepool}
      description: security group that only enables ssh
      vpc_id: ${data.aws_vpc.the_vpc.id}
      ingress:
        - from_port: 22
        to_port: 22
        protocol: TCP
        cidr_blocks:
          - 0.0.0.0/0
      tags:
        Environment: ${var.vpc_name}
        Organization: ${var.organization_name}
        Name: ssh_eks_${var.vpc_name}-nodepool-${var.nodepool}
