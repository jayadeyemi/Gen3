#!/usr/bin/env python3
"""
terraform_copy_and_split.py

Copy a Terraform directory to a temporary workspace and process
Terraform files to split blocks by type and module, then purge originals.
"""
import os
import re
import shutil
import argparse
import tempfile

# Regex to capture any first word as block type
BLOCK_START_RE = re.compile(r'^\s*(?P<type>[A-Za-z_][A-Za-z0-9_-]*)\b')

# Regex to capture module name
MODULE_NAME_RE = re.compile(r'^\s*module\s+"([^"]+)"', re.IGNORECASE)

def split_and_purge(root_dir: str):
    for dirpath, _, filenames in os.walk(root_dir):
        # Gather all original .tf files
        orig_files = [os.path.join(dirpath, f)
                      for f in filenames if f.endswith('.tf')]
        if not orig_files:
            continue

        collected = {}  # non-module blocks
        modules = {}    # module blocks

        # Extract blocks from each file
        for full_path in orig_files:
            with open(full_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            i = 0
            while i < len(lines):
                line = lines[i]
                m = BLOCK_START_RE.match(line)
                if m:
                    btype = m.group('type')
                    blk = [line]
                    balance = line.count('{') - line.count('}')
                    i += 1
                    while i < len(lines) and balance > 0:
                        blk.append(lines[i])
                        balance += lines[i].count('{') - lines[i].count('}')
                        i += 1
                    if not blk[-1].endswith('\n'):
                        blk[-1] += '\n'
                    content = ''.join(blk)

                    if btype.lower() == 'module':
                        name_match = MODULE_NAME_RE.match(blk[0])
                        key = name_match.group(1) if name_match else 'unknown'
                        modules.setdefault(key, []).append(content)
                    else:
                        collected.setdefault(btype, []).append(content)
                    continue
                i += 1

        # Write module-specific files
        for name, blocks in modules.items():
            out = os.path.join(dirpath, f"{name}.tf")
            with open(out, 'w', encoding='utf-8') as f:
                f.writelines(blocks)
            # print(f"Wrote {len(blocks)} module '{name}' blocks to {out}")

        # Write aggregated block-type files
        for btype, blocks in collected.items():
            out = os.path.join(dirpath, f"{btype}.tf")
            with open(out, 'w', encoding='utf-8') as f:
                f.writelines(blocks)
            # print(f"Wrote {len(blocks)} '{btype}' blocks to {out}")

        # Delete all original .tf files
        for path in orig_files:
            if os.path.exists(path):
                os.remove(path)
                # print(f"Deleted original file: {path}")

def main():
    parser = argparse.ArgumentParser(
        description="Copy Terraform directory and split files."
    )
    parser.add_argument(
        'source_dir',
        help="Path to the Terraform project directory to copy"
    )
    parser.add_argument(
        'work_dir',
        help="Workspace directory to copy into (default: autogenerated temp dir)"
    )
    args = parser.parse_args()

    src = os.path.abspath(args.source_dir)
    if not os.path.isdir(src):
        print(f"Source directory does not exist: {src}")
        return

    # Prepare workspace
    if args.work_dir:
        work = os.path.abspath(args.work_dir)
        if os.path.exists(work):
            shutil.rmtree(work)
        shutil.copytree(src, work)
    else:
        work = tempfile.mkdtemp(prefix='tf_split_')
        shutil.copytree(src, work, dirs_exist_ok=True)

    # print(f"Copied '{src}' to temporary workspace '{work}'")
    split_and_purge(work)
    # print("Processing complete.")

if __name__ == "__main__":
    main()
